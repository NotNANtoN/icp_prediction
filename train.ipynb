{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169c4255-7bc4-4ff2-b2fd-0587eabe2b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arg_utils import is_notebook, get_cfg\n",
    "cfg = get_cfg()\n",
    "# choices\n",
    "classical_models = [\"linear\", \"xgb\", \"rf\"]\n",
    "nn_models = [\"mlp\", \"rnn\", \"clip\", \"gpt\"]\n",
    "# override variables to experiment in notebook\n",
    "if is_notebook():    \n",
    "    cfg[\"auto_lr_find\"] = False\n",
    "    cfg[\"outer_folds\"] = 0\n",
    "    cfg[\"target_name\"] = \"ICP_Vital\"   # ICP_Vital\" , long_icp_hypertension_2\n",
    "    cfg[\"db_name\"] = \"UKE\"  # \"UKE\", \"MIMIC\", \"eICU\"\n",
    "    cfg[\"minutes\"] = 60\n",
    "    cfg[\"model_type\"] = \"rnn\"\n",
    "    cfg[\"gpt_name\"] = \"gpt2\"  # distilgpt2, gpt2, gpt2-medium, gpt2-large(too large)\n",
    "    cfg[\"reduction_factor\"] = 16\n",
    "    \n",
    "    cfg[\"randomly_mask_aug\"] = 0.1\n",
    "    cfg[\"target_nan_quantile\"] = 0.9999\n",
    "    cfg[\"target_clip_quantile\"] = 0.999\n",
    "\n",
    "    # do experiments on:  fill_type, target_nan_quantile, train_noise_std, \n",
    "    #  min_len(increase from 20 to higher), grad_clip_val (at 1 so far), weight_decay (at 0.2 so far)\n",
    "    \n",
    "    cfg[\"fill_type\"] = \"none\" # \"pat_mean\", \"median\", \"pat_ema\" \"pat_ema_mask\"\n",
    "    #cfg[\"norm_method\"] = None # z, or none\n",
    "    \n",
    "    cfg[\"bs\"] = 16 # 8 best for rnn, 32 for GPT\n",
    "\n",
    "\n",
    "    # classical model args\n",
    "    cfg[\"flat_block_size\"] = 1\n",
    "    # general args\n",
    "    cfg[\"max_epochs\"] = 20\n",
    "    cfg[\"use_nan_embed\"] = True\n",
    "    cfg[\"norm_nan_embed\"] = True\n",
    "    cfg[\"weight_decay\"] = 0.0\n",
    "    cfg[\"grad_clip_val\"] = 1.0\n",
    "    cfg[\"use_huber\"] = 0\n",
    "    \n",
    "    cfg[\"lr\"] = 1e-4\n",
    "    cfg[\"agg_meds\"] = True\n",
    "    \n",
    "    \n",
    "    # rnn params\n",
    "    cfg[\"hidden_size\"] = 2048\n",
    "    cfg[\"rnn_type\"] = \"gru\"\n",
    "    cfg[\"rnn_layers\"] = 1\n",
    "    \n",
    "    \n",
    "    # transformer stats for gpt2\n",
    "    # 4.338-4.8GB with adapters and batch size 16 and 117 secs\n",
    "    # 6.620GB with adapters and batch size 32 and only 100 secs\n",
    "    # 11.074 GB with adapters and batch size 64 and 92 secs\n",
    "    # also 4.864GB with train_mlp_norm and 127 secss\n",
    "    # all get to r2 of around 0.48\n",
    "\n",
    "    # transformer stats for gptneo1.3\n",
    "    # bs8 2.1GB, \n",
    "\n",
    "    # rnn stats for hidden layers size 2048\n",
    "    # bs 64, 5084MB, 40 secs.\n",
    "    # bs 128, 8632MB, 38 secs.\n",
    "\n",
    "    # transformer params\n",
    "    cfg[\"mode\"] = \"adapters\"  # \"adapters\", \"train_mlp_norm\",  \"train_norm\", \"freeze\" (does not train)\n",
    "    cfg[\"gpu\"] = 1\n",
    "    \n",
    "    cfg[\"seed\"] = 0\n",
    "    cfg[\"subsample\"] = 0.9\n",
    "    cfg[\"colsample_bytree\"] = 0.9\n",
    "    \n",
    "    \n",
    "    \n",
    "# overrides and calculated default vals\n",
    "if cfg[\"lr\"] is None:\n",
    "    model_type = cfg[\"model_type\"]\n",
    "    if model_type == \"clip\":\n",
    "        cfg[\"lr\"] = 0.001\n",
    "    elif model_type == \"gpt\":\n",
    "        # bs 8 and gpt2 take 9.8GB with max seq len of 512\n",
    "        # bs 16 with max seq len of 256\n",
    "        # bs 32 with max seq len 128 only 7.4GB, good performance and fast - 6.9 if mlp_norm\n",
    "        # bs 64 with len 128 and mlp_norm = 10.9GB. 9.4GB for freeze\n",
    "        cfg[\"lr\"] = 0.00005\n",
    "    else:\n",
    "        cfg[\"lr\"] = 0.0001  # 0.01 works kind of for nan_embed\n",
    "\n",
    "if cfg[\"fill_type\"] == \"none\":\n",
    "    cfg[\"use_nan_embed\"] = 1\n",
    "        \n",
    "#cfg[\"val_check_interval\"] = int(cfg[\"val_check_interval\"] * (32 / cfg[\"batch_size\"]))\n",
    "    \n",
    "import pytorch_lightning as pl\n",
    "pl.utilities.seed.seed_everything(seed=cfg[\"seed\"], workers=False)\n",
    "locals().update(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f4c780-09b5-4421-a595-a1e1d47cb861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(cfg[\"gpu\"])\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "import pytorch_lightning\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "pytorch_lightning.utilities.distributed.log.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10ef0e1-e32d-46c5-b1ba-64c282c82091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df\n",
    "path = f'data/DB_{cfg[\"db_name\"]}_{cfg[\"minutes\"]}_final_df.parquet'\n",
    "df = pd.read_parquet(path)\n",
    "print(df.shape)\n",
    "# drop columns that are completely NaN\n",
    "df = df.dropna(axis=1, how=\"all\")\n",
    "print(df.shape)\n",
    "# drop columns that are completely zero\n",
    "mean_zeros = (df == 0).mean()\n",
    "df = df[list(mean_zeros[mean_zeros < 1.0].index)]\n",
    "#df = df[((df == 0).mean() < 0.9999).index]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d55bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(df[\"ICP_Vital\"].describe())\n",
    "print(df.isna().mean().mean())\n",
    "print(df[\"ICP_Vital\"].isna().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db715a-8709-4a85-bbe1-6a2a6de3287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datamodule with dataloaders\n",
    "\n",
    "from train_utils import make_train_val_fold\n",
    "\n",
    "dms = make_train_val_fold(df, cfg, cfg[\"outer_folds\"])\n",
    "dm = dms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e89898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print quantiles\n",
    "train_ds = dm.train_ds\n",
    "print(\"NaN quantiles:\", train_ds.lower_target_nan_quantile, train_ds.upper_target_nan_quantile)\n",
    "print(\"Clip quantiles:\", train_ds.lower_target_clip_quantile, train_ds.upper_target_clip_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c97ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_ds.feature_names))\n",
    "train_ds.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc46f5e-6dc0-47e3-898f-b3a20dbd425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataloader\n",
    "out = next(iter(dm.train_dataloader()))\n",
    "inputs, targets, lens = next(iter(dm.train_dataloader()))\n",
    "#print(dm.feature_names)\n",
    "print(inputs.shape, inputs.min(), inputs.max())\n",
    "print(targets.shape)\n",
    "print(targets[~torch.isnan(targets)].mean())\n",
    "print(lens)\n",
    "print(lens.float().mean(), lens.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b4ee0-f3cb-4547-86bd-5c16750fb475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model on datamodule\n",
    "from train_utils import train_model\n",
    "\n",
    "models, trainers = train_model(cfg[\"model_type\"], dms, cfg, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff8cd7d-4d53-464e-a8c8-33093791304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61581bf3-7516-4515-8e13-5cada07fac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils\n",
    "from eval_utils import get_all_dfs, print_all_metrics\n",
    "import importlib\n",
    "importlib.reload(eval_utils)\n",
    "# eval\n",
    "dl_type = \"val\"\n",
    "#dl = external_dls[\"MIMIC\"] # external_dls - MIMIC, eICU, UKE\n",
    "calc_new_norm_stats = False\n",
    "dl = None\n",
    "\n",
    "pred_df = get_all_dfs(models, trainers, cfg[\"model_type\"], dm.regression, dl_type=dl_type,\n",
    "                      dl=dl, calc_new_norm_stats=calc_new_norm_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba348af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25455a66-a68b-45d4-af3b-aeeef8295957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import eval_utils\n",
    "importlib.reload(eval_utils)\n",
    "from eval_utils import get_all_dfs, hypertension_acc, hypertension_auc\n",
    "\n",
    "\n",
    "if dm.regression:\n",
    "    #from eval_utils import hypertension_acc\n",
    "    pred_targets = pred_df[\"targets\"].dropna()\n",
    "    preds = pred_df[\"preds\"][~pred_df[\"targets\"].isna()]\n",
    "    print(\"Baseline acc for hypertension: \", hypertension_acc(pred_targets, np.zeros((len(pred_targets,)))))\n",
    "    print(\"Accuracy for hypertension: \", hypertension_acc(pred_targets, preds))\n",
    "    print(\"AUC for hypertension: \", hypertension_auc(pred_targets, preds))\n",
    "\n",
    "    print_all_metrics(pred_df)\n",
    "else:\n",
    "    # general metrics\n",
    "    non_na_pred_df = pred_df.dropna(subset=[\"targets\"])\n",
    "    binary_preds = non_na_pred_df[\"preds\"] > 0.5\n",
    "    targets = non_na_pred_df[\"targets\"] \n",
    "    preds = non_na_pred_df[\"preds\"]\n",
    "    \n",
    "    \n",
    "    auc = sklearn.metrics.roc_auc_score(targets, preds)\n",
    "    tpr, fpr, threshs = sklearn.metrics.roc_curve(targets, preds)\n",
    "    plt.plot(tpr, fpr)\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"black\")\n",
    "    plt.show()\n",
    "    \n",
    "    precision, recall, thresholds = sklearn.metrics.precision_recall_curve(targets, preds)\n",
    "    plt.plot(precision, recall)\n",
    "    plt.xlabel(\"precision\")\n",
    "    plt.ylabel(\"recall\")\n",
    "    plt.show()\n",
    "    \n",
    "    matrix = sklearn.metrics.confusion_matrix(non_na_pred_df[\"targets\"],\n",
    "                                              binary_preds)\n",
    "    cm_display = sklearn.metrics.ConfusionMatrixDisplay(matrix).plot()\n",
    "    print(matrix)\n",
    "    print(\"AUC: \", auc)\n",
    "    print(\"Mean pred: \", pred_df[\"preds\"].mean())\n",
    "    \n",
    "    #train_pred_df = get_all_dfs(models, trainers, cfg[\"model_type\"], dm.regression, dl_type=\"train\", dl=None, calc_new_norm_stats=False)\n",
    "    #non_na_df = train_pred_df.dropna(subset=[\"targets\"])\n",
    "    #tpr, fpr, threshs = sklearn.metrics.roc_curve(non_na_df[\"targets\"], non_na_df[\"preds\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef71db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_utils import r2_score\n",
    "df_nona = pred_df.dropna(subset=[\"targets\"]).reset_index()\n",
    "# macro R2\n",
    "baseline = dm.preprocessor.mean_train_target\n",
    "df_nona.groupby(\"ids\").apply(lambda pat: r2_score(pat[\"targets\"], pat[\"preds\"], baseline_target=baseline)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c408a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.train_ds.preprocessor.mean_train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74323e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_nona[\"preds\"]).hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a00b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nona[\"targets\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nona[\"preds\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e8559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.preprocessor.mean_train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67621cc-d191-4566-bd7c-99272804fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dm.regression:\n",
    "    df_nona = pred_df.dropna(subset=[\"targets\"]).reset_index()\n",
    "    mean_pred_error = (df_nona[\"targets\"] - dm.preprocessor.mean_train_target).dropna() ** 2\n",
    "    error = (df_nona[\"targets\"] - df_nona[\"preds\"]) ** 2\n",
    "    df_nona[\"error\"] = error\n",
    "    ax = sns.jointplot(x=\"targets\", y=\"error\", data=df_nona, kind=\"hist\", bins=100) # data=by_pat\n",
    "    ax.ax_joint.scatter(df_nona[\"targets\"], (np.ones(len(df_nona[\"targets\"])) * dm.preprocessor.mean_train_target - df_nona[\"targets\"]) ** 2, s=2, color=\"orange\")\n",
    "    plt.xlim(-20, 105)\n",
    "    plt.ylim(0, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a2abb-6845-4293-9415-5dd5adc9f9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dm.regression:\n",
    "    ylim = (df_nona[\"preds\"].min() - 5, df_nona[\"preds\"].max() + 5)\n",
    "    ax = sns.jointplot(data=df_nona, x=\"targets\", y=\"preds\", kind=\"reg\", ylim=ylim) # data=bypat\n",
    "    min_val = df_nona[\"targets\"].min()\n",
    "    max_val = df_nona[\"targets\"].max()\n",
    "    ax.ax_joint.plot([min_val, max_val], [min_val, max_val], linewidth=2, color=\"black\", label=\"Ideal model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad86cce3-b09a-417c-9b1e-df32bd376f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dm.regression:\n",
    "    ax = sns.jointplot(data=df_nona, x=\"targets\", y=\"preds\", kind=\"hist\", bins=100, ylim=ylim)\n",
    "    print(min_val, max_val)\n",
    "    # draw line of perfect correlation\n",
    "    ax.ax_joint.plot([min_val, max_val], [min_val, max_val], linewidth=2)#, color=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d524c7bd-4af2-40be-8e94-36653d2a39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dm.regression:\n",
    "    #pats = df.groupby(\"ids\").filter(lambda x: x['preds'].max() > 16)\n",
    "    pats = pred_df.groupby(\"ids\").filter(lambda x: x['targets'].mean() > 20)\n",
    "    #pats = df.groupby(\"ids\").filter(lambda x: np.sqrt(x['error'].mean()) > 30)\n",
    "else:\n",
    "    pats = pred_df.groupby(\"ids\").filter(lambda x: x['preds'].mean() > 0.2)\n",
    "pats = pats.groupby(\"ids\").filter(lambda x: len(x[\"targets\"].dropna()) > 2)\n",
    "\n",
    "ids = pats[\"ids\"].unique()\n",
    "print(ids)\n",
    "print(len(ids), \"patients\")\n",
    "#pats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9539f8f6-a2e1-44a2-9f8f-b59374bc0365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_utils import mape\n",
    "import sklearn\n",
    "\n",
    "pat_id = 1\n",
    "model_id = 0\n",
    "\n",
    "pat = pred_df[pred_df[\"ids\"] == ids[pat_id]]\n",
    "pat = pat[pat[\"model_id\"] == model_id]\n",
    "plt.scatter(pat[\"step\"], pat[\"targets\"], label=\"targets\", color=\"orange\")\n",
    "plt.plot(pat[\"step\"], pat[\"preds\"], label=\"preds\")\n",
    "mean = dm.preprocessor.mean_train_target\n",
    "print(\"mean average target: \", mean)\n",
    "print(\"mean pat targets: \", pat[\"targets\"].mean())\n",
    "plt.plot([0, max(pat[\"step\"])], [mean, mean], linewidth=1, color=\"black\", label=\"mean train target\", linestyle=\"--\")\n",
    "plt.plot([0, max(pat[\"step\"])], [22, 22], linewidth=1, color=\"red\", label=\"critical\", linestyle=\":\")\n",
    "\n",
    "#plt.legend(location=\"out\")\n",
    "plt.legend(title='Legend', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xlim(0, max(pat[\"step\"]) + 1)\n",
    "pat_nona = pat[~pat[\"targets\"].isna()]\n",
    "print(\"R2 of model: \", sklearn.metrics.r2_score(pat_nona[\"targets\"], pat_nona[\"preds\"]))\n",
    "print(\"RMSE of model:\", round(np.sqrt(sklearn.metrics.mean_squared_error(pat_nona[\"targets\"], pat_nona[\"preds\"])), 2))\n",
    "print(\"RMSE of mean:\", round(np.sqrt(sklearn.metrics.mean_squared_error(pat_nona[\"targets\"], [mean] * len(pat_nona))), 2))\n",
    "print(\"MAPE of model: \", round(mape(pat_nona[\"targets\"], pat_nona[\"preds\"]), 2))\n",
    "print(\"MAPE of mean: \", round(mape(pat_nona[\"targets\"], [mean] * len(pat_nona)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ffe0a-eee1-4cce-b1be-49438b10b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(dm.train_ds.targets)):\n",
    "#    d = dm.train_ds.targets[i]\n",
    "#    d = d[~torch.isnan(d)].max()\n",
    "#    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1a9b2-fc96-44fc-ae9a-b36d3ba15adb",
   "metadata": {},
   "source": [
    "## Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92051d2-6364-4ea0-b135-fb1a36742866",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = dm.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1894b92-2011-446f-8a54-c61e63545836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "\n",
    "def classical_saliency(models, trainers, model_type, use_shap=False, verbose=True):\n",
    "    # plot feature importance\n",
    "    all_importances = []\n",
    "    all_inputs = []\n",
    "    \n",
    "    for model, data_module in zip(models, trainers):\n",
    "        if use_shap:\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            inputs = data_module.test_dataloader().dataset.flat_inputs\n",
    "            importances = explainer.shap_values(inputs)\n",
    "            all_inputs.append(inputs)\n",
    "        else:\n",
    "            if hasattr(model, \"feature_importances_\"):\n",
    "                importances = model.feature_importances_\n",
    "            elif hasattr(model, \"coef_\"):\n",
    "                importances = model.coef_\n",
    "        all_importances.append(importances)\n",
    "    if not use_shap and verbose and hasattr(model, \"importance_type\"):\n",
    "        print(\"Importance type: \", model.importance_type)\n",
    "    print(\"importances shape \", importances.shape)\n",
    "    mean_importances = np.mean(np.stack(all_importances), axis=0)\n",
    "    # save\n",
    "    path = f\"outputs/{model_type}\"\n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    \n",
    "    block_size = cfg[\"flat_block_size\"]\n",
    "\n",
    "    \n",
    "    if use_shap:\n",
    "        #shap.summary_plot(mean_importances, X_test, plot_type=\"bar\")\n",
    "        #shap.summary_plot(mean_importances, X_test)\n",
    "        #shap.summary_plot(mean_importances)\n",
    "        #input_df = pd.DataFrame(inputs, columns=feature_names)\n",
    "        #shap_df = pd.DataFrame(mean_importances, columns=feature_names)\n",
    "        \n",
    "        #vals= np.abs(shap_values).mean(0)\n",
    "        #feature_importance = pd.DataFrame(list(zip(feature_names, vals)),columns=['col_name','feature_importance_vals'])\n",
    "        #feature_importance = feature_importance.sort_values(by=['feature_importance_vals'], ascending=False)\n",
    "        #feature_importance.head()\n",
    "                \n",
    "        if verbose:\n",
    "            block_feat_names = []\n",
    "            for i in range(block_size):\n",
    "                block_feat_names.extend([f + f\"_{i}\" for f in feature_names])\n",
    "            \n",
    "            shap.summary_plot(mean_importances, features=inputs, \n",
    "                              feature_names=block_feat_names)\n",
    "            plt.savefig(path + \"_shap_importances.jpg\", bbox_inches='tight')\n",
    "        \n",
    "        \n",
    "        # average over block_size/time_steps\n",
    "       \n",
    "        if block_size > 1:\n",
    "            print(mean_importances.shape)\n",
    "            mean_importances = mean_importances.reshape(-1, len(feature_names), block_size).mean(axis=-1)\n",
    "            print(mean_importances.shape)\n",
    "\n",
    "\n",
    "        imp_per_feat = np.abs(mean_importances).mean(axis=0)\n",
    "        feat_df = pd.Series(imp_per_feat, index=feature_names)\n",
    "    else:\n",
    "        # make plot\n",
    "        if block_size > 1:\n",
    "            print(mean_importances.shape)\n",
    "            mean_importances = np.abs(mean_importances.reshape(len(feature_names), block_size)).mean(axis=-1)\n",
    "            print(mean_importances.shape)\n",
    "        \n",
    "        \n",
    "        feat_df = pd.Series(mean_importances, index=feature_names)\n",
    "        if verbose:\n",
    "            p = feat_df.sort_values().plot.barh(figsize=(4, 25))\n",
    "            p.figure.savefig(path + \"_importances.jpg\", bbox_inches='tight')\n",
    "        \n",
    "    feat_df = feat_df.sort_values(ascending=True)\n",
    "    return feat_df\n",
    "\n",
    "\n",
    "def reduce_feat_df(feat_df, threshold=0.2):\n",
    "    # remove everything above 90% explained importance\n",
    "    print(len(feat_df))\n",
    "    feat_df = feat_df / feat_df.sum()\n",
    "    reduced_df = feat_df[feat_df.cumsum() > threshold]\n",
    "    print(len(reduced_df))\n",
    "    print(reduced_df.sum())\n",
    "    print(reduced_df)\n",
    "    reduced_feats = list(reduced_df.index)\n",
    "    return reduced_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d1290-dae4-4e8b-a146-7432f517b1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5cbf78-fa03-46d4-8b25-9a79cebc967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg[\"model_type\"] in [\"xgb\", \"log\"]:\n",
    "    sal_df = classical_saliency(models, trainers, cfg[\"model_type\"], \n",
    "                                use_shap=True, verbose=True)\n",
    "    \n",
    "    sal_df_normed = sal_df / sal_df.sum()\n",
    "    sal_df_normed.sort_values().iloc[-10:]\n",
    "    \n",
    "    reduced_feats = reduce_feat_df(sal_df, threshold=0.15)\n",
    "    reduced_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ef0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1796a280-7dea-4b4b-8f0c-652c7bdfe8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import saliency\n",
    "from saliency import get_sal_list\n",
    "import importlib\n",
    "importlib.reload(saliency)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "sal_list = []\n",
    "for model in models:\n",
    "    model.cuda()\n",
    "    max_backprop_len = 128 \n",
    "    model_saliency = get_sal_list(model, 0, perc=1.0, agg=True, ds=model.data_module.val_dataloader().dataset, ig=False, max_len=max_backprop_len)\n",
    "    sal_list.append(model_saliency)\n",
    "    model.cpu()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6abc5e-34bc-4e2b-bd36-ee849884ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58887d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sal_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d8408-dd00-42c3-9276-d87371240738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: average over multiple models!\n",
    "#for sal in sal_list:\n",
    "\n",
    "mean_overall = [s.mean(0) for s in sal_list[0]]\n",
    "feat_saliency = np.sum(mean_overall, axis=0)\n",
    "feature_names = dm.feature_names\n",
    "feat_sal_df = pd.DataFrame({\"sal\": feat_saliency}, index = feature_names).sort_values(\"sal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27d5fa3-8796-462c-bcb5-b8200f84aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "p = feat_sal_df.plot.barh(figsize = (6, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856c47c1-4cbc-4575-83c7-017102979484",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.figure.savefig(\"importances.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff7d4bb-3f7f-4b41-b3a2-b4542cfd892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc965d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0847682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6228fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal = sal_list[0]\n",
    "\n",
    "all_steps = []\n",
    "for i, s in enumerate(sal):\n",
    "    pat_df = pd.DataFrame(s, columns=feature_names)\n",
    "    pat_df[\"pat_id\"] = i\n",
    "    pat_df[\"step\"] = np.arange(s.shape[0])\n",
    "    all_steps.append(pat_df)\n",
    "sal_df = pd.concat(all_steps, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af466a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kick out pats with less than 4 measurements\n",
    "sal_df_min_four = sal_df[sal_df.groupby(\"pat_id\").step.transform(len) >= 4]\n",
    "# calculate N averaged steps per patient\n",
    "N = 4\n",
    "averaged_df = []\n",
    "for pat_id in sal_df_min_four.pat_id.unique():\n",
    "    pat_df = sal_df_min_four[sal_df_min_four.pat_id == pat_id]\n",
    "    parts = np.array_split(pat_df, N)\n",
    "    for part in parts:\n",
    "        averaged_df.append(part.mean())\n",
    "averaged_df = pd.DataFrame(averaged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c2a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train umap on averaged steps\n",
    "from umap import UMAP\n",
    "umapper = UMAP(n_neighbors=10, min_dist=0.1)\n",
    "sal_data = averaged_df.drop(columns=[\"pat_id\", \"step\"])\n",
    "umap_embedding = umapper.fit_transform(sal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9c1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot umap\n",
    "import umap.plot\n",
    "#umap.plot.points(umapper, labels=averaged_df.pat_id)\n",
    "umap.plot.points(umapper, values=averaged_df.step, theme=\"fire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616b57a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster averaged using K-means\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=0)\n",
    "#clustering_data = sal_data\n",
    "clustering_data = umap.UMAP(n_neighbors=10, min_dist=0.1).fit_transform(sal_data)\n",
    "kmeans.fit(clustering_data)\n",
    "cluster_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b39432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label histogram\n",
    "plt.figure()\n",
    "plt.hist(cluster_labels, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c81ab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot clusters\n",
    "plt.figure()\n",
    "plt.scatter(umap_embedding[:, 0], umap_embedding[:, 1], c=cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1429af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad52e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print boxplot for each feature per clusters\n",
    "for i in range(np.max(cluster_labels) + 1):\n",
    "    cluster_data = sal_data[cluster_labels == i]\n",
    "    # sort feature columns by absolute value\n",
    "    mean_abs = cluster_data.abs().mean(axis=0)\n",
    "    sorted_data = sorted(cluster_data.transpose().values, key=lambda x: np.abs(x).mean())\n",
    "    sorted_columns = sorted(cluster_data.columns, key=lambda x: np.abs(cluster_data[x]).mean())\n",
    "    # only show top N\n",
    "    N = 10\n",
    "    sorted_data = sorted_data[-N:] \n",
    "    sorted_columns = sorted_columns[-N:]\n",
    "    \n",
    "    # now sort by mean value without abs\n",
    "    mean_data = cluster_data.mean(axis=0)\n",
    "    sorted_data = sorted(sorted_data, key=lambda x: x.mean())\n",
    "    sorted_columns = sorted(sorted_columns, key=lambda x: mean_data[x])\n",
    "    \n",
    "    # show boxplot where the feature name is at the y-axis\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.boxplot(sorted_data, labels=sorted_columns, whis=1.5, vert=False)\n",
    "    plt.show()\n",
    "    # show variant where each single point is shown\n",
    "    #plt.figure(figsize=(5, 5))\n",
    "    #plt.scatter(cluster_data.index, cluster_data[sorted_columns[0]], c=cluster_labels)\n",
    "    sorted_df = pd.DataFrame(sorted_data, index=sorted_columns)\n",
    "    \n",
    "    sns.stripplot(data=sorted_df.transpose(), orient=\"h\", palette=\"Set2\", color=\".25\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478830b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(data=sorted_df.transpose(), orient=\"h\", palette=\"Set2\", color=\".25\")\n",
    "sns.boxplot(data=sorted_df.transpose(), orient=\"h\", palette=\"Set2\", showfliers=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6efc0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b51139e8-1e0d-4967-8899-0c8671e7bf05",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3786fb1d-890a-41a6-92bd-143ad740bead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tune_utils import tune#, make_tune_plots\n",
    "from data_utils import make_split\n",
    "\n",
    "import importlib\n",
    "import tune_utils\n",
    "importlib.reload(tune_utils)\n",
    "from tune_utils import tune\n",
    "\n",
    "import data_utils\n",
    "importlib.reload(data_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f60c1-a0a6-4f25-9391-3b051cd022c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pytorch_lightning\n",
    "\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
    "pytorch_lightning.utilities.distributed.log.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b319e7b2-fde0-4ad7-8414-3e3a8fc2f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg[\"dbs\"] = [\"UKE\"]\n",
    "cfg[\"k_fold\"] = 0\n",
    "cfg[\"num_splits\"] = 3\n",
    "cfg[\"flat_block_size\"] = 0\n",
    "cfg[\"n_trials\"] = 15\n",
    "cfg[\"model_type\"] = \"linear\"\n",
    "cfg[\"fill_type\"] = \"pat_mean\"\n",
    "\n",
    "cfg[\"max_steps\"] = 300\n",
    "\n",
    "opt_flat_block_size = False\n",
    "opt_augs = False\n",
    "opt_fill_type = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6193a76c-b789-4845-a4e5-6eaa5eae3e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storage = optuna.storages.RDBStorage(url=\"sqlite:///optuna.db\",\n",
    "#                                         engine_kwargs={\"connect_args\": {\"timeout\": 30}})\n",
    "#load_study = optuna.load_study(\"09_17_02_39__linear_UKE_15\", storage=storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d751b3c-3c64-48df-9d5b-ff2b2b09f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dev/test split to test tuning\n",
    "dev_data, test_data, dev_idcs, test_idcs = make_split(seq_list, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5afe9b-7da5-46ec-8f67-98fd4bbce52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune\n",
    "study = tune(dev_data, test_data, args, cfg, verbose=False, n_trials=cfg[\"n_trials\"],\n",
    "             opt_flat_block_size=opt_flat_block_size, opt_augs=opt_augs, opt_fill_type=opt_fill_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59314a06-f83a-4a4b-a50b-c02700a2ad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_idcs = np.load(\"test_tune/09_17_02_39__linear_UKE_15/test_idcs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159b05d2-0a2b-4599-adb1-321e0bbe31bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print key study parts\n",
    "name = study.study_name\n",
    "print(name)\n",
    "print(study.best_trial)\n",
    "best_params = study.best_params\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc29766-69c1-4e9f-92ab-7afd708fab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tune_utils import store_study_results\n",
    "store_study_results(study, \"./test_tune/\", test_idcs, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe860988-bd2b-4c89-bdce-4955b336eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_tune_plots(study, f\"outputs/tune_results/{cfg['model_type']}_{cfg['n_trials']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99161a6f-167e-4bca-9e0b-7f438fc7fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain on dev/test and check performance\n",
    "    \n",
    "models, trainers = retrain(dev_data, test_data, best_params, args, cfg, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f74412f-3003-43f0-ab14-e3caefd6dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg[\"k_fold\"] = 0\n",
    "cfg[\"num_splits\"] = 5\n",
    "models, trainers = retrain(dev_data, test_data, best_params, args, cfg, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f840e-3eb0-4558-8a45-971b7cf3aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg[\"k_fold\"] = 5\n",
    "models, trainers = retrain(dev_data, test_data, best_params, args, cfg, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448055bd-c960-4fd5-90ae-d67cace0f033",
   "metadata": {},
   "source": [
    "## Nested k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9144be8-e705-41ef-8750-b4eb7d799c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classical_models = [\"xgb\", \"rf\", \"linear\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af294171-1ca8-4627-b19a-76355ec58389",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg[\"dbs\"] = [\"UKE\"]\n",
    "cfg[\"k_fold\"] = 0\n",
    "cfg[\"num_splits\"] = 3\n",
    "cfg[\"flat_block_size\"] = 1\n",
    "cfg[\"n_trials\"] = 10\n",
    "\n",
    "cfg[\"n_outer_folds\"] = 3\n",
    "\n",
    "cfg[\"model_type\"] = \"xgb\"\n",
    "cfg[\"fill_type\"] = \"pat_mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f058455f-207d-4d20-adf1-10ee74dc84c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import make_fold\n",
    "# outer fold\n",
    "dev_data_list, test_data_list, dev_idcs, test_idcs = make_fold(seq_list, k=cfg[\"n_outer_folds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae3167-5c9c-45f3-835b-2a01cb2673b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune and store studies\n",
    "studies = []\n",
    "for dev_data, test_data in zip(dev_data_list, test_data_list):\n",
    "    study = tune(dev_data, test_data, args, cfg, verbose=False, n_trials=cfg[\"n_trials\"])\n",
    "    # print key tune details\n",
    "    name = study.study_name\n",
    "    print(name)\n",
    "    print(study.best_trial)\n",
    "    best_params = study.best_params\n",
    "    print(best_params)\n",
    "    studies.append(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207d300d-5dfd-47c4-9e7d-3cbfc2df82de",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "pred_dfs = []\n",
    "for tune_idx in tqdm(range(len(studies))):\n",
    "    models, trainers = retrain(dev_data_list[tune_idx],\n",
    "                               test_data_list[tune_idx], \n",
    "                               studies[tune_idx].best_params, \n",
    "                               args, cfg, verbose=False)\n",
    "    df = get_all_dfs(models, trainers, cfg[\"model_type\"], dl_type=\"test\")\n",
    "    #loss = print_all_metrics(df)\n",
    "    loss = df.groupby(\"model_id\").apply(lambda model_df: model_df.groupby(\"ids\").mean()).mean()[\"error\"]\n",
    "    metrics.append(loss)\n",
    "    pred_dfs.append(df)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0db61e-746e-4f46-901d-b0694fbd631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(metrics))\n",
    "print(np.std(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dafaf53-4484-4f4a-9e53-28744b3327c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for study in studies:\n",
    "    print(study.best_value)\n",
    "    print(study.best_params)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58bb9ad-48e6-4594-9ce6-6857ebab6e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "[study.best_value for study in studies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a480c0c7-70f3-4ea3-bae3-08b2b18dc0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60af506-40aa-40f8-9821-ac6ea982ac74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d452de-db1a-4e25-96ca-aac754aa9aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(metrics))\n",
    "print(np.std(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79480ff-c1be-4238-9ae2-d5cf3228bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for study in studies:\n",
    "    print(study.best_value)\n",
    "    print(study.best_params)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1236125c-e54d-4d13-9fd8-3d763e1b2de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6858ffd-9c76-4cb5-bd0c-d8d3298a5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43776d9b-3083-45f3-a58b-5b118f6680e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "studies[0].best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0cdda2-cc87-483e-af97-b508505f3d55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
