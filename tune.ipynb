{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8249040-0da5-4a4c-9120-eb8fa64cc0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2\n"
     ]
    }
   ],
   "source": [
    "from arg_utils import is_notebook, get_cfg\n",
    "cfg = get_cfg()\n",
    "# choices\n",
    "classical_models = [\"linear\", \"xgb\", \"rf\"]\n",
    "nn_models = [\"mlp\", \"rnn\", \"transformer\", \"clip\", \"gpt\"]\n",
    "# override variables to experiment in notebook\n",
    "if is_notebook():    \n",
    "    cfg[\"target_name\"] = \"ICP_Vital\"   # ICP_Vital\" , long_icp_hypertension_2\n",
    "    cfg[\"db_name\"] = \"UKE\"  # \"UKE\", \"MIMIC\"\n",
    "    cfg[\"minutes\"] = 60\n",
    "    cfg[\"model_type\"] = \"rnn\"\n",
    "    \n",
    "    # do experiments on:fill_type, target_nan_quantile, train_noise_std, \n",
    "    #  min_len(increase from 20 to higher), grad_clip_val (at 1 so far), weight_decay (at 0.2 so far)\n",
    "    \n",
    "    cfg[\"fill_type\"] = \"median\" # \"pat_mean\", \"median\", \"pat_ema\" \"pat_ema_mask\"\n",
    "    cfg[\"norm_method\"] = None # z, or none\n",
    "\n",
    "    \n",
    "    cfg[\"bs\"] = 32 # 8 best for rnn, 32 for GPT\n",
    "    cfg[\"max_len\"] = 128\n",
    "    cfg[\"min_len\"] = 128\n",
    "    cfg[\"target_nan_quantile\"] = 0.9999\n",
    "    cfg[\"block_size\"] = 0\n",
    "\n",
    "    # classical model args\n",
    "    cfg[\"flat_block_size\"] = 8\n",
    "    # general args\n",
    "    cfg[\"max_epochs\"] = 20\n",
    "    cfg[\"use_nan_embed\"] = False\n",
    "    cfg[\"weight_decay\"] = 0.2\n",
    "    \n",
    "    \n",
    "    # rnn params\n",
    "    cfg[\"hidden_size\"] = 2048\n",
    "    cfg[\"rnn_type\"] = \"gru\"\n",
    "    \n",
    "    # transformer params\n",
    "    cfg[\"mode\"] = \"train_mlp_norm\"  # \"adapters\", \"train_mlp_norm\",  \"train_norm\", \"freeze\" (does not train)\n",
    "    \n",
    "    cfg[\"gpu\"] = 1\n",
    "    \n",
    "    \n",
    "# overrides and calculated default vals\n",
    "if cfg[\"lr\"] is None:\n",
    "    model_type = cfg[\"model_type\"]\n",
    "    if model_type == \"clip\":\n",
    "        cfg[\"lr\"] = 0.001\n",
    "    elif model_type == \"gpt\":\n",
    "        # bs 8 and gpt2 take 9.8GB with max seq len of 512\n",
    "        # bs 16 with max seq len of 256\n",
    "        # bs 32 with max seq len 128 only 7.4GB, good performance and fast - 6.9 if mlp_norm\n",
    "        # bs 64 with len 128 and mlp_norm = 10.9GB. 9.4GB for freeze\n",
    "        cfg[\"lr\"] = 0.00005\n",
    "    else:\n",
    "        cfg[\"lr\"] = 0.0001  # 0.01 works kind of for nan_embed\n",
    "        \n",
    "#cfg[\"val_check_interval\"] = int(cfg[\"val_check_interval\"] * (32 / cfg[\"batch_size\"]))\n",
    "    \n",
    "import pytorch_lightning as pl\n",
    "pl.utilities.seed.seed_everything(seed=cfg[\"seed\"], workers=False)\n",
    "locals().update(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e611fa-7e8b-4b19-a8ad-e5de8b0d03e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu)\n",
    "# disable wandb printing\n",
    "os.environ['WANDB_SILENT'] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b989845a-f790-4c8a-ad2a-a8dcfc39edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "        \n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_utils import SeqDataModule\n",
    "\n",
    "import logging\n",
    "import pytorch_lightning\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "pytorch_lightning.utilities.distributed.log.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586c73b5-b346-4caa-85ac-ae7d70d940fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df\n",
    "path = f\"data/DB_{db_name}_{minutes}_final_df.pkl\"\n",
    "df = pd.read_pickle(path)\n",
    "\n",
    "if \"Bili_BGA\" in df:\n",
    "    print(\"Drop Bili\")\n",
    "    df = df.drop(columns=[\"Bili_BGA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08b132-be9d-490b-9471-0f39f9d0330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import copy\n",
    "\n",
    "from train_utils import train_model\n",
    "from data_utils import SeqDataModule\n",
    "from eval_utils import get_all_dfs\n",
    "\n",
    "def obj_hebo(*args, **kwargs):\n",
    "    return np.array([obj(*args, **kwargs)])\n",
    "    \n",
    "\n",
    "def obj(df, cfg, opt_df, num_seeds=3, split=\"val\"):\n",
    "    # put in op_df\n",
    "    cfg = copy.deepcopy(cfg)\n",
    "    if isinstance(opt_df, pd.DataFrame):\n",
    "        opt_dict = opt_df.iloc[0].to_dict()\n",
    "    else:\n",
    "        opt_dict = opt_df\n",
    "    if \"bs\" in opt_dict:\n",
    "        opt_dict[\"bs\"] = int(opt_dict[\"bs\"])\n",
    "    cfg.update(opt_dict)\n",
    "    cfg = scale_hyperparameters(cfg)\n",
    "    if cfg[\"fill_type\"] == \"none\":\n",
    "        cfg[\"use_nan_embed\"] = True\n",
    "    # calculate metrics for number of seeds\n",
    "    if num_seeds is None:\n",
    "        metric = train_and_eval_model(df, cfg, split=split)\n",
    "    else:\n",
    "        metrics = []\n",
    "        for seed in range(num_seeds):\n",
    "            cfg[\"seed\"] = seed\n",
    "            metrics.append(train_and_eval_model(df, cfg, split=split))\n",
    "        metric = np.mean(metrics)\n",
    "    return metric\n",
    "\n",
    "\n",
    "def scale_hyperparameters(opt_df):\n",
    "    if \"bs\" in opt_df:\n",
    "        opt_df[\"bs\"] = 2 ** opt_df[\"bs\"]\n",
    "    if \"n_estimators\" in opt_df:\n",
    "        opt_df[\"n_estimators\"] *= 10\n",
    "\n",
    "    if \"train_noise_std\" in opt_df:\n",
    "        opt_df[\"train_noise_std\"] = opt_df[\"train_noise_std\"] * 0.1\n",
    "\n",
    "    if \"weight_decay\" in opt_df:\n",
    "        opt_df[\"weight_decay\"] = opt_df[\"weight_decay\"] * 0.1\n",
    "\n",
    "    if \"grad_clip_val\" in opt_df:\n",
    "        opt_df[\"grad_clip_val\"] = opt_df[\"grad_clip_val\"] * 0.1\n",
    "\n",
    "    return opt_df\n",
    "\n",
    "\n",
    "def train_and_eval_model(df, cfg, split):\n",
    "    dm, models, trainers = setup_dm_and_train(df, cfg)\n",
    "    metric = eval_model(dm, models, trainers, cfg, split)\n",
    "    return metric\n",
    "\n",
    "def setup_dm_and_train(df, cfg):\n",
    "    # create datamodule with dataloaders\n",
    "    dm = SeqDataModule(df, cfg[\"db_name\"],\n",
    "                       target_name=cfg[\"target_name\"],\n",
    "                       random_starts=cfg[\"random_starts\"], \n",
    "                       min_len=cfg[\"min_len\"], \n",
    "                       max_len=cfg[\"max_len\"],\n",
    "                       train_noise_std=cfg[\"train_noise_std\"], \n",
    "                       batch_size=cfg[\"bs\"], \n",
    "                       fill_type=cfg[\"fill_type\"], \n",
    "                       flat_block_size=cfg[\"flat_block_size\"],\n",
    "                       target_nan_quantile=cfg[\"target_nan_quantile\"],\n",
    "                       block_size=cfg[\"block_size\"],\n",
    "                       )\n",
    "    dm.setup()\n",
    "    # train model on datamodule\n",
    "    models, trainers = train_model(cfg[\"model_type\"], [dm], cfg, verbose=False)\n",
    "    return dm, models, trainers\n",
    "\n",
    "def eval_model(dm, models, trainers, cfg, split):\n",
    "    # make preds on val set\n",
    "    pred_df = get_all_dfs(models, trainers, cfg[\"model_type\"], dm.regression, dl_type=split, dl=None, calc_new_norm_stats=False)\n",
    "    \n",
    "    # calc target metrics\n",
    "    pred_targets = pred_df[\"targets\"].dropna()\n",
    "    preds = pred_df[\"preds\"][~pred_df[\"targets\"].isna()]\n",
    "    if dm.regression:\n",
    "        score = sklearn.metrics.r2_score(pred_targets, preds)\n",
    "    else:\n",
    "        score = sklearn.metrics.roc_auc_score(pred_targets, preds)\n",
    "    metric = 1 - score\n",
    "        \n",
    "    return np.array([metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe8067d-fc71-4766-80ed-a6f4d510b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from hebo.design_space.design_space import DesignSpace\n",
    "from hebo.optimizers.hebo import HEBO\n",
    "\n",
    "if cfg[\"model_type\"] in [\"rnn\", \"gpt\", \"mlp\"]:\n",
    "    space = DesignSpace().parse([{'name': 'lr', 'type' : 'num', 'lb' : 0.00001, 'ub' : 0.1},\n",
    "                                 {'name': 'bs', 'type' : 'int', 'lb' : 2, 'ub' : 5},  # 2 ** bs\n",
    "                                 \n",
    "                                 {'name': 'fill_type', 'type' : 'cat', 'categories' : ['median', 'none']},\n",
    "                                 \n",
    "                                 #{'name': 'min_len', 'type' : 'int', 'lb': 2, 'ub':128},\n",
    "                                 #{'name': 'max_len', 'type' : 'int', 'lb': 64, 'ub':512},\n",
    "                                 \n",
    "                                 {'name': 'train_noise_std', 'type' : 'int', 'lb' : 0, 'ub' : 2},\n",
    "                                 {'name': 'weight_decay', 'type' : 'int', 'lb' : 0, 'ub' : 4},\n",
    "                                 {'name': 'grad_clip_val', 'type' : 'int', 'lb' : 0, 'ub' : 5},\n",
    "                                 #{'name': 'norm_method', 'type' : 'cat', 'categories' : [\"z\", None]},\n",
    "                                ])\n",
    "    cfg[\"fill_type\"] = \"none\"\n",
    "    opt = HEBO(space)\n",
    "elif cfg[\"model_type\"] == \"xgb\":\n",
    "    space = DesignSpace().parse([{'name': 'lr', 'type' : 'num', 'lb' : 0.00005, 'ub' : 0.5},\n",
    "                                 {'name': 'n_estimators', 'type' : 'int', 'lb' : 1, 'ub' : 20},  # multiplied by 10\n",
    "                                 {'name': 'max_depth', 'type' : 'int', 'lb' : 2, 'ub' : 10},\n",
    "                                 {'name': 'subsample', 'type' : 'num', 'lb' : 0.5, 'ub' : 0.99},\n",
    "                                 {'name': 'colsample_bytree', 'type' : 'num', 'lb' : 0.5, 'ub' : 0.99},\n",
    "                                 {'name': 'gamma', 'type' : 'num', 'lb' : 0.01, 'ub' : 5.0},\n",
    "                                 {'name': 'min_child_weight', 'type' : 'num', 'lb' : 0.01, 'ub' : 5},\n",
    "                                 \n",
    "                                 {'name': 'fill_type', 'type' : 'cat', 'categories' : ['median', 'none']},\n",
    "                                 {'name': 'flat_block_size', 'type' : 'int', 'lb' : 1, 'ub' : 4}\n",
    "                                ])\n",
    "    #cfg[\"flat_block_size\"] = 8\n",
    "\n",
    "\n",
    "tune_hebo = cfg[\"tune_hebo\"]\n",
    "\n",
    "if tune_hebo:\n",
    "    opt = HEBO(space, rand_sample=0,\n",
    "            model_name=\"gpy\")#\"rf\")#\"gpy\")\n",
    "\n",
    "    opt_steps = cfg[\"opt_steps\"]\n",
    "\n",
    "    cfg[\"verbose\"] = False\n",
    "\n",
    "    for i in range(opt_steps):\n",
    "        rec = opt.suggest()\n",
    "        print(i)\n",
    "        print(list(zip(rec.columns, rec.values[0])))\n",
    "        start_time = time.time()\n",
    "        opt.observe(rec, obj_hebo(df, cfg, rec))\n",
    "        print(\"Opt time: \", time.time() - start_time)\n",
    "        min_idx = np.argmin(opt.y)\n",
    "        print(\"Current score:\", 1 - opt.y[-1][0])\n",
    "        print(f'After {i} iterations, best obj is {1 - opt.y[min_idx][0]:.4f}')\n",
    "        print()\n",
    "\n",
    "    opt_df = opt.X\n",
    "    opt_df[\"y\"] = opt.y\n",
    "    opt_df[\"y\"].plot()\n",
    "    opt_df[\"score\"] = 1 - opt_df[\"y\"]\n",
    "\n",
    "    plt.show()\n",
    "    opt_df.plot.scatter(x=\"lr\", y=\"score\")\n",
    "    plt.show()\n",
    "\n",
    "    # create a folder to save the results\n",
    "    import os\n",
    "    import datetime\n",
    "    # create folder name according to the database name, minutes, model type and date\n",
    "    folder_name = f\"hebo_tunings/{cfg['db_name']}_{cfg['minutes']}/{cfg['model_type']}_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    # save the results\n",
    "    opt_df.to_csv(f\"{folder_name}/results.csv\", index=False)\n",
    "\n",
    "\n",
    "    # one-hot encode\n",
    "    input_df = opt.X.drop(columns=[\"y\"])\n",
    "    if \"score\" in input_df:\n",
    "        input_df = input_df.drop(columns=[\"score\"])\n",
    "\n",
    "    if \"fill_type\" in input_df:\n",
    "        one_hot_fill = pd.get_dummies(opt.X.fill_type, prefix='fill')\n",
    "        input_df = pd.concat([input_df, one_hot_fill], axis=1).drop(columns=[\"fill_type\"]).astype(float)\n",
    "    else:\n",
    "        input_df = input_df.astype(float)\n",
    "\n",
    "    # feat importance using rf\n",
    "    rf = sklearn.ensemble.RandomForestRegressor(100)\n",
    "    rf.fit(input_df, 1 - opt.y)\n",
    "    pd.Series(data=rf.feature_importances_, index=input_df.columns).sort_values()\n",
    "\n",
    "    import shap\n",
    "    expl = shap.TreeExplainer(rf, data=input_df, model_output='raw', \n",
    "                            feature_perturbation='interventional')\n",
    "    shap_vals = expl.shap_values(input_df, check_additivity=False)\n",
    "    shap.summary_plot(shap_vals, input_df.astype(float))\n",
    "    plt.show()\n",
    "\n",
    "    mean_shap_vals = np.abs(shap_vals).mean(axis=0)\n",
    "    mean_shap_vals /= mean_shap_vals.sum()\n",
    "    pd.Series(data=mean_shap_vals, index=input_df.columns).sort_values().plot.bar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c264f0-e741-4004-9f41-5282bdabbc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OPTUNA\n",
    "\n",
    "import optuna\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Invoke suggest methods of a Trial object to generate hyperparameters.\n",
    "    if cfg[\"model_type\"] in [\"rnn\", \"gpt\", \"mlp\"]:\n",
    "        rec = {'lr': trial.suggest_float(\"lr\", 0.00005, 0.1),\n",
    "               #'min_len': trial.suggest_int(\"min_len\", 2, 128),\n",
    "               #'train_noise_std': trial.suggest_float(\"train_noise_std\", 0.001, 0.2),\n",
    "               #'weight_decay': trial.suggest_float(\"weight_decay\", 0.001, 0.4),\n",
    "               #'grad_clip_val': trial.suggest_float(\"grad_clip_val\", 0.1, 5.0),   \n",
    "               #'train_noise_std': trial.suggest_int(\"train_noise_std\", 0, 2),\n",
    "               'weight_decay': trial.suggest_int(\"weight_decay\", 0, 4),\n",
    "               'grad_clip_val': trial.suggest_int(\"grad_clip_val\", 0, 5),               \n",
    "               #'fill_type': trial.suggest_categorical(\"fill_type\", [\"median\", \"none\"]),\n",
    "            }\n",
    "\n",
    "        if cfg[\"model_type\"] == \"gpt\":\n",
    "            rec[\"bs\"] = trial.suggest_int(\"bs\", 2, 5)\n",
    "        else:\n",
    "            rec[\"bs\"] = trial.suggest_int(\"bs\", 2, 5)\n",
    "        #cfg[\"fill_type\"] = \"none\"\n",
    "    elif cfg[\"model_type\"] == \"xgb\":\n",
    "        rec = {'lr': trial.suggest_float(\"lr\", 0.00005, 0.5),\n",
    "           'n_estimators': trial.suggest_int(\"n_estimators\", 1, 20),\n",
    "           'max_depth': trial.suggest_int(\"max_depth\", 2, 10),\n",
    "           'subsample': trial.suggest_float(\"subsample\", 0.5, 0.99),\n",
    "           'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.5, 0.99),\n",
    "           'gamma': trial.suggest_float(\"gamma\", 0.01, 5.0),\n",
    "           'min_child_weight': trial.suggest_float(\"min_child_weight\", 0.01, 5.0),\n",
    "           'fill_type': trial.suggest_categorical(\"fill_type\", [\"median\", \"none\"]),\n",
    "           'flat_block_size': trial.suggest_int(\"flat_block_size\", 1, 4),\n",
    "          }\n",
    "    \n",
    "    for key in rec:\n",
    "        rec[key] = [rec[key]]\n",
    "    rec = pd.DataFrame(rec)\n",
    "    \n",
    "    error = obj(df, cfg, rec)\n",
    "    return error  \n",
    "\n",
    "\n",
    "study = optuna.create_study()  # Create a new study.\n",
    "study.optimize(objective, n_trials=cfg[\"opt_steps\"])  # Invoke optimization of the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caca371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a folder to save the results\n",
    "import os\n",
    "import datetime\n",
    "# create folder name according to the database name, minutes, model type and date\n",
    "folder_name = f\"tunings/{cfg['db_name']}_{cfg['minutes']}/{cfg['model_type']}_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# create a dataframe with the results\n",
    "tune_result_df = pd.DataFrame(study.trials_dataframe())\n",
    "tune_result_df[\"score\"] = 1 - tune_result_df[\"value\"]\n",
    "tune_result_df.to_csv(f\"{folder_name}/results.csv\")\n",
    "\n",
    "def save_plot(name):\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{folder_name}/{name}.png\")\n",
    "    plt.close()\n",
    "\n",
    "optuna.visualization.plot_slice(study)\n",
    "save_plot(\"slice\")\n",
    "optuna.visualization.plot_param_importances(study)\n",
    "save_plot(\"param_importances\")\n",
    "optuna.visualization.plot_optimization_history(study)\n",
    "save_plot(\"optimization_history\")\n",
    "if cfg[\"model_type\"] in [\"rnn\", \"gpt\", \"mlp\"]:\n",
    "    optuna.visualization.plot_contour(study, params=[\"lr\", \"bs\", \"weight_decay\", \"grad_clip_val\"]),\n",
    "    save_plot(\"contour\")\n",
    "    optuna.visualization.plot_intermediate_values(study),\n",
    "    save_plot(\"intermediate_values\")\n",
    "else:\n",
    "    optuna.visualization.plot_contour(study, params=[\"lr\", \"n_estimators\", \"max_depth\", \"subsample\", \"colsample_bytree\", \"gamma\", \"min_child_weight\"]),\n",
    "    save_plot(\"contour\")\n",
    "    optuna.visualization.plot_intermediate_values(study),\n",
    "    save_plot(\"intermediate_values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1023e7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_bs</th>\n",
       "      <th>params_grad_clip_val</th>\n",
       "      <th>params_lr</th>\n",
       "      <th>params_weight_decay</th>\n",
       "      <th>state</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.488807</td>\n",
       "      <td>2022-03-11 14:49:08.823950</td>\n",
       "      <td>2022-03-11 14:53:09.510202</td>\n",
       "      <td>0 days 00:04:00.686252</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.080372</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>0.511193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.481927</td>\n",
       "      <td>2022-03-11 14:53:09.510349</td>\n",
       "      <td>2022-03-11 14:57:07.848430</td>\n",
       "      <td>0 days 00:03:58.338081</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.028529</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>0.518073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.444031</td>\n",
       "      <td>2022-03-11 14:57:07.848561</td>\n",
       "      <td>2022-03-11 15:00:12.246134</td>\n",
       "      <td>0 days 00:03:04.397573</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030603</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>0.555969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number     value             datetime_start          datetime_complete  \\\n",
       "0       0  0.488807 2022-03-11 14:49:08.823950 2022-03-11 14:53:09.510202   \n",
       "1       1  0.481927 2022-03-11 14:53:09.510349 2022-03-11 14:57:07.848430   \n",
       "2       2  0.444031 2022-03-11 14:57:07.848561 2022-03-11 15:00:12.246134   \n",
       "\n",
       "                duration  params_bs  params_grad_clip_val  params_lr  \\\n",
       "0 0 days 00:04:00.686252          4                     1   0.080372   \n",
       "1 0 days 00:03:58.338081          4                     4   0.028529   \n",
       "2 0 days 00:03:04.397573          5                     2   0.030603   \n",
       "\n",
       "   params_weight_decay     state     score  \n",
       "0                    4  COMPLETE  0.511193  \n",
       "1                    1  COMPLETE  0.518073  \n",
       "2                    1  COMPLETE  0.555969  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_result_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262606b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_type': 'rnn', 'target_name': 'ICP_Vital', 'db_name': 'UKE', 'minutes': 60, 'seed': 2, 'features': None, 'fill_type': 'none', 'target_nan_quantile': 0.9999, 'block_size': 0, 'random_starts': True, 'train_noise_std': 0.001, 'bs': 32, 'min_len': 128, 'max_len': 128, 'max_epochs': 20, 'lr': 0.03060312028749815, 'use_nan_embed': True, 'weight_decay': 0.1, 'grad_clip_val': 0.2, 'val_check_interval': None, 'max_steps': -1, 'use_macro_loss': False, 'use_pos_weight': True, 'use_huber': False, 'dropout': 0.1, 'hidden_size': 2048, 'use_static': False, 'rnn_layers': 1, 'rnn_type': 'gru', 'mode': 'train_mlp_norm', 'clip_name': 'ViT-B/16', 'gpt_name': 'gpt2', 'flat_block_size': 8, 'alpha': 1, 'l1_ratio': 0.5, 'n_estimators': 500, 'max_depth': 6, 'min_child_weight': None, 'gamma': 0.0, 'subsample': 1.0, 'colsample_bytree': 1.0, 'tree_method': 'gpu_hist', 'norm_method': None, 'gpu': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models with best parameters:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models with best parameters:  20%|██        | 1/5 [01:03<04:12, 63.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models with best parameters:  40%|████      | 2/5 [02:15<03:26, 68.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models with best parameters:  60%|██████    | 3/5 [03:38<02:30, 75.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models with best parameters:  80%|████████  | 4/5 [04:42<01:10, 70.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models with best parameters: 100%|██████████| 5/5 [05:45<00:00, 69.02s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_407463/3951979609.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_score_mean\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_score_std\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mbest_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{folder_name}/best_params.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# save cfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "# get the best hyperparameters\n",
    "best_trial = study.best_trial\n",
    "best_params = best_trial.params\n",
    "\n",
    "\n",
    "# train the model with the best hyperparameters and test it on test split\n",
    "def train_and_test(df, cfg, best_params, num_seeds=5):\n",
    "    cfg = copy.deepcopy(cfg)\n",
    "    # put the best hyperparameters in the config\n",
    "    cfg.update(best_params)\n",
    "    cfg = scale_hyperparameters(cfg)\n",
    "    if cfg[\"fill_type\"] == \"none\":\n",
    "        cfg[\"use_nan_embed\"] = True\n",
    "\n",
    "    print(cfg)\n",
    "\n",
    "    val_scores = []\n",
    "    test_scores = []\n",
    "    for seed in tqdm(range(num_seeds), desc=\"Training models with best parameters\"):\n",
    "        cfg[\"seed\"] = seed\n",
    "\n",
    "        dm, models, trainers = setup_dm_and_train(df, cfg)\n",
    "        val_metric = eval_model(dm, models, trainers, cfg, \"val\")\n",
    "        test_metric = eval_model(dm, models, trainers, cfg, \"test\")\n",
    "        val_score = 1 - val_metric\n",
    "        test_score = 1 - test_metric\n",
    "        val_scores.append(val_score)\n",
    "        test_scores.append(test_score)\n",
    "    return val_scores, test_scores\n",
    "val_scores, test_scores = train_and_test(df, cfg, best_params, num_seeds=5)\n",
    "\n",
    "# store best params and scores in a dataframe\n",
    "df = pd.DataFrame(best_params, index=[0])\n",
    "df[\"val_score_mean\"] = np.mean(val_scores)\n",
    "df[\"val_score_std\"] = np.std(val_scores)\n",
    "df[\"test_score_mean\"] = np.mean(test_scores)\n",
    "df[\"test_score_std\"] = np.std(test_scores)\n",
    "df.to_csv(f\"{folder_name}/best_params.csv\")\n",
    "\n",
    "# save cfg\n",
    "import json\n",
    "with open(f\"{folder_name}/cfg.json\", \"w+\") as f:\n",
    "    json.dump(cfg, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9882386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store best params and scores in a dataframe\n",
    "df = pd.DataFrame(best_params, index=[0])\n",
    "df[\"val_score_mean\"] = np.mean(val_scores)\n",
    "df[\"val_score_std\"] = np.std(val_scores)\n",
    "df[\"test_score_mean\"] = np.mean(test_scores)\n",
    "df[\"test_score_std\"] = np.std(test_scores)\n",
    "df.to_csv(f\"{folder_name}/best_params.csv\")\n",
    "\n",
    "# save cfg\n",
    "import json\n",
    "with open(f\"{folder_name}/cfg.json\", \"w+\") as f:\n",
    "    json.dump(cfg, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5b3eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>grad_clip_val</th>\n",
       "      <th>bs</th>\n",
       "      <th>val_score_mean</th>\n",
       "      <th>val_score_std</th>\n",
       "      <th>test_score_mean</th>\n",
       "      <th>test_score_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030603</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.55132</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>0.616117</td>\n",
       "      <td>0.02301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lr  weight_decay  grad_clip_val  bs  val_score_mean  val_score_std  \\\n",
       "0  0.030603             1              2   5         0.55132       0.002324   \n",
       "\n",
       "   test_score_mean  test_score_std  \n",
       "0         0.616117         0.02301  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5c1b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raw",
   "language": "python",
   "name": "raw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
